#!/usr/bin/env python3
"""
check_frontmatter.py - 9251205claude.mdãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯æº–æ‹ ãƒ•ãƒ­ãƒ³ãƒˆãƒã‚¿ãƒ¼æ¤œè¨¼ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

æ©Ÿèƒ½:
- document_idå½¢å¼æ¤œè¨¼ï¼ˆTYPE-DOMAIN-NNNï¼‰
- key_conceptsé…åˆ—æ¤œè¨¼
- related_docsé…åˆ—ã¨relationshipå€¤æ¤œè¨¼
- next_review/review_cycle_daysæ•´åˆæ€§æ¤œè¨¼
- ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚¿ã‚¤ãƒ—åˆ¥å¿…é ˆã‚»ã‚¯ã‚·ãƒ§ãƒ³æ¤œè¨¼
- CI/CDé€£æºå¯¾å¿œï¼ˆçµ‚äº†ã‚³ãƒ¼ãƒ‰ã€JSONå‡ºåŠ›ï¼‰

çµ‚äº†ã‚³ãƒ¼ãƒ‰:
- 0: æˆåŠŸï¼ˆã‚¨ãƒ©ãƒ¼ãªã—ï¼‰
- 1: ã‚¨ãƒ©ãƒ¼ã‚ã‚Šï¼ˆå¿…é ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰æ¬ è½ã€å½¢å¼ä¸æ­£ï¼‰
- 2: è­¦å‘Šã‚ã‚Šï¼ˆæ¨å¥¨ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰æ¬ è½ï¼‰

ä½¿ç”¨æ–¹æ³•:
  python check_frontmatter.py [--format json] [--schema-dir PATH] [--check-sections]
"""

import argparse
import json
import os
import re
import sys
from datetime import datetime, timedelta
from pathlib import Path
from typing import Any

import yaml

# =============================================================================
# å®šæ•°å®šç¾©
# =============================================================================

# document_idå½¢å¼: TYPE-DOMAIN-NNN (ä¾‹: PRC-DATA-001, PLB-INC-002)
DOCUMENT_ID_PATTERN = re.compile(r'^[A-Z]{2,4}-[A-Z]{2,4}-\d{3}$')

# ADRå½¢å¼ã‚‚è¨±å®¹: ADR-NNNN
ADR_ID_PATTERN = re.compile(r'^ADR-\d{4}$')

# æœ‰åŠ¹ãªãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚¿ã‚¤ãƒ—
VALID_TYPES = ['policy', 'sop', 'playbook', 'runbook', 'cheatsheet', 'adr',
               'process', 'troubleshooting', 'guide', 'specification']

# æœ‰åŠ¹ãªã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹
VALID_STATUSES = ['draft', 'review', 'approved', 'active', 'deprecated', 'superseded']

# æœ‰åŠ¹ãªrelationshipå€¤
VALID_RELATIONSHIPS = [
    'implements',      # ã“ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãŒãã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’å®Ÿè£…
    'governed-by',     # ã“ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãŒãã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®ç®¡ç†ä¸‹
    'references',      # å˜ç´”ãªå‚ç…§é–¢ä¿‚
    'depends-on',      # å‰ææ¡ä»¶ã¨ã—ã¦ä¾å­˜
    'escalates-to',    # å¤±æ•—æ™‚ã®ã‚¨ã‚¹ã‚«ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å…ˆ
    'supersedes',      # ã“ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãŒç½®ãæ›ãˆã‚‹
    'superseded-by'    # ã“ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ç½®ãæ›ãˆã‚‹ã‚‚ã®
]

# æœ‰åŠ¹ãªãƒ‰ãƒ¡ã‚¤ãƒ³
VALID_DOMAINS = ['infrastructure', 'security', 'data', 'application',
                 'scientific', 'operations', 'documentation',
                 'data-analysis', 'cfd', 'gis', 'visualization']  # å¾Œæ–¹äº’æ›æ€§

# æœ‰åŠ¹ãªã‚ªãƒ¼ãƒ‡ã‚£ã‚¨ãƒ³ã‚¹
VALID_AUDIENCES = ['developers', 'operators', 'architects', 'scientists', 'all']

# å¿…é ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ï¼ˆ9251205claude.mdæº–æ‹ ï¼‰
REQUIRED_FIELDS = [
    'document_id', 'title', 'type', 'version', 'status',
    'owner', 'author', 'created', 'updated',
    'tags', 'key_concepts', 'summary',
    'domain', 'audience'
]

# æ¨å¥¨ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰
RECOMMENDED_FIELDS = [
    'next_review', 'review_cycle_days', 'related_docs',
    'difficulty', 'priority'
]

# å¾Œæ–¹äº’æ›æ€§ãƒãƒƒãƒ”ãƒ³ã‚°
LEGACY_FIELD_MAPPING = {
    'category': 'type',
    'created_at': 'created',
    'updated_at': 'updated',
    'description': 'summary'
}

# =============================================================================
# YAMLè§£æ
# =============================================================================

def extract_frontmatter(file_path: Path) -> tuple[dict | None, str]:
    """YAMLãƒ•ãƒ­ãƒ³ãƒˆãƒã‚¿ãƒ¼ã‚’æŠ½å‡ºã—ã¦è§£æã™ã‚‹"""
    with open(file_path, 'r', encoding='utf-8') as f:
        content = f.read()

    if not content.startswith('---'):
        return None, content

    parts = content.split('---', 2)
    if len(parts) < 3:
        return None, content

    frontmatter_text = parts[1]
    body = parts[2] if len(parts) > 2 else ''

    try:
        # YAMLã¨ã—ã¦è§£æï¼ˆã‚³ãƒ¡ãƒ³ãƒˆä»˜ãã§ã‚‚å¯¾å¿œï¼‰
        frontmatter = yaml.safe_load(frontmatter_text)
        if frontmatter is None:
            frontmatter = {}
        return frontmatter, body
    except yaml.YAMLError:
        # YAMLãƒ‘ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼æ™‚ã¯ç°¡æ˜“çš„ãªè¡Œè§£æã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
        frontmatter = parse_frontmatter_fallback(frontmatter_text)
        return frontmatter, body


def parse_frontmatter_fallback(text: str) -> dict:
    """YAMLãƒ‘ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼æ™‚ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯è§£æ"""
    result = {}
    current_key = None
    current_array = None

    for line in text.split('\n'):
        # ã‚³ãƒ¡ãƒ³ãƒˆè¡Œã‚’ã‚¹ã‚­ãƒƒãƒ—
        stripped = line.strip()
        if not stripped or stripped.startswith('#'):
            continue

        # é…åˆ—ã‚¢ã‚¤ãƒ†ãƒ ã®å‡¦ç†
        if stripped.startswith('- '):
            if current_array is not None:
                value = stripped[2:].strip().strip('"\'')
                # ãƒã‚¹ãƒˆã•ã‚ŒãŸã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆï¼ˆä¾‹: path:, relationship:ï¼‰
                if ':' in value and not value.startswith('<!--'):
                    # ç°¡æ˜“çš„ã«ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã¨ã—ã¦å‡¦ç†
                    obj = {}
                    for part in stripped[2:].split(','):
                        if ':' in part:
                            k, v = part.split(':', 1)
                            obj[k.strip()] = v.strip().strip('"\'')
                    result[current_array].append(obj)
                else:
                    result[current_array].append(value)
            continue

        # ã‚­ãƒ¼: å€¤ã®å‡¦ç†
        if ':' in line:
            key_part, value_part = line.split(':', 1)
            key = key_part.strip()

            # ã‚³ãƒ¡ãƒ³ãƒˆã‚’é™¤å»
            if not key.startswith('#'):
                value = value_part.strip()
                # ã‚¤ãƒ³ãƒ©ã‚¤ãƒ³ã‚³ãƒ¡ãƒ³ãƒˆã‚’é™¤å»
                if '#' in value and not value.startswith('"'):
                    value = value.split('#')[0].strip()

                # é…åˆ—ã®é–‹å§‹ã‚’æ¤œå‡º
                if value == '' or value == '[]':
                    result[key] = []
                    current_array = key
                    current_key = None
                else:
                    value = value.strip('"\'')
                    result[key] = value
                    current_key = key
                    current_array = None

    return result

def extract_sections(body: str) -> list[str]:
    """Markdownæœ¬æ–‡ã‹ã‚‰H2ã‚»ã‚¯ã‚·ãƒ§ãƒ³åã‚’æŠ½å‡º"""
    sections = []
    for line in body.split('\n'):
        if line.startswith('## '):
            # çµµæ–‡å­—ã‚„ãƒãƒ¼ã‚¯ã‚’é™¤å»ã—ã¦ã‚»ã‚¯ã‚·ãƒ§ãƒ³åã‚’å–å¾—
            section_name = line[3:].strip()
            # çµµæ–‡å­—ã‚’é™¤å»
            section_name = re.sub(r'^[\U0001F300-\U0001F9FF\u2600-\u26FF\u2700-\u27BF]+\s*', '', section_name)
            sections.append(section_name)
    return sections

# =============================================================================
# æ¤œè¨¼é–¢æ•°
# =============================================================================

def validate_document_id(value: str) -> tuple[bool, str]:
    """document_idå½¢å¼ã‚’æ¤œè¨¼"""
    if not value:
        return False, "document_id is empty"

    # TEMPLATEãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ã‚’ã‚¹ã‚­ãƒƒãƒ—
    if 'TEMPLATE' in value or 'DOMAIN-NNN' in value:
        return True, "template placeholder (skipped)"

    if DOCUMENT_ID_PATTERN.match(value) or ADR_ID_PATTERN.match(value):
        return True, "valid"

    return False, f"invalid format: expected TYPE-DOMAIN-NNN (e.g., PRC-DATA-001), got '{value}'"

def validate_type(value: str) -> tuple[bool, str]:
    """typeãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’æ¤œè¨¼"""
    if not value:
        return False, "type is empty"

    if value.lower() in VALID_TYPES:
        return True, "valid"

    return False, f"invalid type: expected one of {VALID_TYPES}, got '{value}'"

def validate_status(value: str) -> tuple[bool, str]:
    """statusãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’æ¤œè¨¼"""
    if not value:
        return False, "status is empty"

    # TEMPLATEãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ã‚’ã‚¹ã‚­ãƒƒãƒ—
    if 'TEMPLATE' in value:
        return True, "template placeholder (skipped)"

    if value.lower() in VALID_STATUSES:
        return True, "valid"

    return False, f"invalid status: expected one of {VALID_STATUSES}, got '{value}'"

def validate_owner(value: str) -> tuple[bool, str]:
    """ownerãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’æ¤œè¨¼ï¼ˆ@team-nameå½¢å¼ï¼‰"""
    if not value:
        return False, "owner is empty"

    # TEMPLATEãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ã‚’ã‚¹ã‚­ãƒƒãƒ—
    if 'TEMPLATE' in value or value == '@team-name':
        return True, "template placeholder (skipped)"

    if value.startswith('@'):
        return True, "valid"

    return False, f"invalid owner format: expected @team-name, got '{value}'"

def validate_date(value: Any, field_name: str) -> tuple[bool, str]:
    """æ—¥ä»˜ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’æ¤œè¨¼"""
    if not value:
        return False, f"{field_name} is empty"

    # TEMPLATEãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ã‚’ã‚¹ã‚­ãƒƒãƒ—
    if isinstance(value, str) and 'TEMPLATE' in value:
        return True, "template placeholder (skipped)"

    # datetimeã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®å ´åˆ
    if isinstance(value, datetime):
        return True, "valid"

    # æ–‡å­—åˆ—ã®å ´åˆ
    if isinstance(value, str):
        try:
            datetime.strptime(value, '%Y-%m-%d')
            return True, "valid"
        except ValueError:
            return False, f"invalid date format: expected YYYY-MM-DD, got '{value}'"

    return True, "valid (non-string)"

def validate_array(value: Any, field_name: str, min_items: int = 1) -> tuple[bool, str]:
    """é…åˆ—ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’æ¤œè¨¼"""
    if not value:
        return False, f"{field_name} is empty"

    if not isinstance(value, list):
        return False, f"{field_name} should be an array, got {type(value).__name__}"

    if len(value) < min_items:
        return False, f"{field_name} should have at least {min_items} items, got {len(value)}"

    return True, "valid"

def validate_related_docs(value: Any) -> tuple[bool, str, list[str]]:
    """related_docsé…åˆ—ã‚’æ¤œè¨¼"""
    warnings = []

    if not value:
        return True, "not specified (optional)", warnings

    if not isinstance(value, list):
        return False, "related_docs should be an array", warnings

    for i, item in enumerate(value):
        if isinstance(item, dict):
            # pathæ¤œè¨¼
            if 'path' not in item:
                warnings.append(f"related_docs[{i}]: missing 'path'")

            # relationshipæ¤œè¨¼
            if 'relationship' in item:
                rel = item['relationship']
                if rel not in VALID_RELATIONSHIPS:
                    return False, f"related_docs[{i}]: invalid relationship '{rel}', expected one of {VALID_RELATIONSHIPS}", warnings
        elif isinstance(item, str):
            # æ—§å½¢å¼ï¼ˆæ–‡å­—åˆ—ã®ã¿ï¼‰ã‚‚è¨±å®¹
            warnings.append(f"related_docs[{i}]: legacy format (string only), consider using {{path, relationship}} format")

    return True, "valid", warnings

def validate_review_consistency(frontmatter: dict) -> tuple[bool, str]:
    """next_reviewã¨review_cycle_daysã®æ•´åˆæ€§ã‚’æ¤œè¨¼"""
    next_review = frontmatter.get('next_review')
    review_cycle = frontmatter.get('review_cycle_days', 180)
    updated = frontmatter.get('updated')

    if not next_review or not updated:
        return True, "skipped (missing next_review or updated)"

    # TEMPLATEãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ã‚’ã‚¹ã‚­ãƒƒãƒ—
    if isinstance(next_review, str) and 'TEMPLATE' in next_review:
        return True, "template placeholder (skipped)"

    try:
        if isinstance(next_review, str):
            next_review_date = datetime.strptime(next_review, '%Y-%m-%d')
        else:
            next_review_date = next_review

        if isinstance(updated, str):
            updated_date = datetime.strptime(updated, '%Y-%m-%d')
        else:
            updated_date = updated

        expected_review = updated_date + timedelta(days=review_cycle)

        # 30æ—¥ä»¥å†…ã®å·®ã¯è¨±å®¹
        diff = abs((next_review_date - expected_review).days)
        if diff > 30:
            return False, f"next_review ({next_review}) differs from expected ({expected_review.strftime('%Y-%m-%d')}) by {diff} days"

        return True, "valid"
    except (ValueError, TypeError):
        return True, "skipped (date parse error)"

# =============================================================================
# ã‚¹ã‚­ãƒ¼ãƒæ¤œè¨¼
# =============================================================================

def load_schema(schema_dir: Path, doc_type: str) -> dict | None:
    """ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚¿ã‚¤ãƒ—ã«å¯¾å¿œã™ã‚‹ã‚¹ã‚­ãƒ¼ãƒã‚’èª­ã¿è¾¼ã‚€"""
    schema_file = schema_dir / f"{doc_type}.yaml"

    if not schema_file.exists():
        return None

    with open(schema_file, 'r', encoding='utf-8') as f:
        return yaml.safe_load(f)

def validate_sections(body: str, schema: dict) -> tuple[bool, list[str], list[str]]:
    """å¿…é ˆã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®å­˜åœ¨ã‚’æ¤œè¨¼"""
    if not schema or 'sections' not in schema:
        return True, [], []

    actual_sections = extract_sections(body)
    actual_sections_lower = [s.lower() for s in actual_sections]

    missing = []
    found = []

    required_sections = schema.get('sections', {}).get('required', [])

    for section in required_sections:
        section_name = section.get('name', '') if isinstance(section, dict) else section
        # éƒ¨åˆ†ä¸€è‡´ã§æ¤œç´¢
        if any(section_name.lower() in s for s in actual_sections_lower):
            found.append(section_name)
        else:
            missing.append(section_name)

    return len(missing) == 0, missing, found

# =============================================================================
# ãƒ¡ã‚¤ãƒ³æ¤œè¨¼ãƒ­ã‚¸ãƒƒã‚¯
# =============================================================================

def validate_file(file_path: Path, schema_dir: Path | None = None, check_sections: bool = False) -> dict:
    """å˜ä¸€ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œè¨¼"""
    result = {
        'file': str(file_path),
        'has_frontmatter': False,
        'errors': [],
        'warnings': [],
        'info': []
    }

    frontmatter, body = extract_frontmatter(file_path)

    if frontmatter is None:
        result['errors'].append("No frontmatter found")
        return result

    if '_parse_error' in frontmatter:
        result['errors'].append(f"YAML parse error: {frontmatter['_parse_error']}")
        return result

    result['has_frontmatter'] = True

    # å¾Œæ–¹äº’æ›æ€§: ãƒ¬ã‚¬ã‚·ãƒ¼ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’ãƒãƒƒãƒ”ãƒ³ã‚°
    for legacy, new in LEGACY_FIELD_MAPPING.items():
        if legacy in frontmatter and new not in frontmatter:
            frontmatter[new] = frontmatter[legacy]
            result['info'].append(f"Legacy field '{legacy}' mapped to '{new}'")

    # === å¿…é ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰æ¤œè¨¼ ===
    for field in REQUIRED_FIELDS:
        if field not in frontmatter:
            result['errors'].append(f"Missing required field: {field}")

    # === å€‹åˆ¥ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰æ¤œè¨¼ ===

    # document_id
    if 'document_id' in frontmatter:
        valid, msg = validate_document_id(frontmatter['document_id'])
        if not valid:
            result['errors'].append(f"document_id: {msg}")

    # type
    if 'type' in frontmatter:
        valid, msg = validate_type(frontmatter['type'])
        if not valid:
            result['errors'].append(f"type: {msg}")

    # status
    if 'status' in frontmatter:
        valid, msg = validate_status(frontmatter['status'])
        if not valid:
            result['errors'].append(f"status: {msg}")

    # owner
    if 'owner' in frontmatter:
        valid, msg = validate_owner(frontmatter['owner'])
        if not valid:
            result['errors'].append(f"owner: {msg}")

    # dates
    for date_field in ['created', 'updated', 'next_review']:
        if date_field in frontmatter:
            valid, msg = validate_date(frontmatter[date_field], date_field)
            if not valid:
                result['errors'].append(f"{date_field}: {msg}")

    # arrays
    if 'tags' in frontmatter:
        valid, msg = validate_array(frontmatter['tags'], 'tags', min_items=2)
        if not valid:
            result['errors'].append(f"tags: {msg}")

    if 'key_concepts' in frontmatter:
        valid, msg = validate_array(frontmatter['key_concepts'], 'key_concepts', min_items=1)
        if not valid:
            result['errors'].append(f"key_concepts: {msg}")

    # related_docs
    if 'related_docs' in frontmatter:
        valid, msg, warnings = validate_related_docs(frontmatter['related_docs'])
        if not valid:
            result['errors'].append(f"related_docs: {msg}")
        result['warnings'].extend(warnings)

    # review consistency
    valid, msg = validate_review_consistency(frontmatter)
    if not valid:
        result['warnings'].append(f"Review consistency: {msg}")

    # === æ¨å¥¨ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰æ¤œè¨¼ ===
    for field in RECOMMENDED_FIELDS:
        if field not in frontmatter:
            result['warnings'].append(f"Missing recommended field: {field}")

    # === ã‚»ã‚¯ã‚·ãƒ§ãƒ³æ¤œè¨¼ ===
    if check_sections and schema_dir:
        doc_type = frontmatter.get('type', '').lower()
        schema = load_schema(schema_dir, doc_type)

        if schema:
            valid, missing, found = validate_sections(body, schema)
            if not valid:
                result['errors'].append(f"Missing required sections: {', '.join(missing)}")
            if found:
                result['info'].append(f"Found required sections: {', '.join(found)}")

    return result

def check_files(base_dir: Path, schema_dir: Path | None = None, check_sections: bool = False) -> list[dict]:
    """æŒ‡å®šãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã®Markdownãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œè¨¼"""
    results = []

    for subdir in ['templates', 'examples']:
        dir_path = base_dir / subdir
        if not dir_path.exists():
            continue

        for md_file in sorted(dir_path.glob('*.md')):
            if md_file.name == 'README.md':
                continue

            result = validate_file(md_file, schema_dir, check_sections)
            result['file'] = str(md_file.relative_to(base_dir))
            results.append(result)

    return results

# =============================================================================
# å‡ºåŠ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
# =============================================================================

def print_text_report(results: list[dict]) -> int:
    """ãƒ†ã‚­ã‚¹ãƒˆå½¢å¼ã§ãƒ¬ãƒãƒ¼ãƒˆã‚’å‡ºåŠ›"""
    total = len(results)
    with_frontmatter = sum(1 for r in results if r['has_frontmatter'])
    error_count = sum(1 for r in results if r['errors'])
    warning_count = sum(1 for r in results if r['warnings'] and not r['errors'])

    print(f"æ¤œè¨¼å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {total}")
    print(f"ãƒ•ãƒ­ãƒ³ãƒˆãƒã‚¿ãƒ¼æœ‰: {with_frontmatter}/{total}")
    print(f"ã‚¨ãƒ©ãƒ¼ã‚ã‚Š: {error_count}/{total}")
    print(f"è­¦å‘Šã®ã¿: {warning_count}/{total}")
    print()

    print("=" * 80)

    for r in results:
        print(f"\nãƒ•ã‚¡ã‚¤ãƒ«: {r['file']}")

        if not r['has_frontmatter']:
            print("  âŒ ãƒ•ãƒ­ãƒ³ãƒˆãƒã‚¿ãƒ¼ãªã—")
            continue

        if r['errors']:
            print("  âŒ ã‚¨ãƒ©ãƒ¼:")
            for err in r['errors']:
                print(f"     - {err}")
        else:
            print("  âœ… å¿…é ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãƒ»å½¢å¼OK")

        if r['warnings']:
            print("  âš ï¸  è­¦å‘Š:")
            for warn in r['warnings']:
                print(f"     - {warn}")

        if r['info']:
            print("  â„¹ï¸  æƒ…å ±:")
            for info in r['info']:
                print(f"     - {info}")

    print("\n" + "=" * 80)

    # ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹ææ¡ˆ
    if error_count > 0:
        print("\nğŸ“š ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹:")
        print("   - document_idå½¢å¼: TYPE-DOMAIN-NNN (ä¾‹: PRC-DATA-001)")
        print("   - relationshipå€¤: implements, governed-by, references, depends-on, escalates-to, supersedes, superseded-by")
        print("   - è©³ç´°ã¯ 1USAGE-GUIDE.md ã‚’å‚ç…§ã—ã¦ãã ã•ã„")

    # çµ‚äº†ã‚³ãƒ¼ãƒ‰æ±ºå®š
    if error_count > 0:
        print(f"\nâŒ æ¤œè¨¼å¤±æ•—: {error_count}ä»¶ã®ã‚¨ãƒ©ãƒ¼")
        return 1
    elif warning_count > 0:
        print(f"\nâš ï¸  æ¤œè¨¼æˆåŠŸï¼ˆè­¦å‘Šã‚ã‚Šï¼‰: {warning_count}ä»¶ã®è­¦å‘Š")
        return 2
    else:
        print(f"\nâœ… æ¤œè¨¼æˆåŠŸ: å…¨{total}ãƒ•ã‚¡ã‚¤ãƒ«ãŒæº–æ‹ ")
        return 0

def print_json_report(results: list[dict]) -> int:
    """JSONå½¢å¼ã§ãƒ¬ãƒãƒ¼ãƒˆã‚’å‡ºåŠ›"""
    total = len(results)
    error_count = sum(1 for r in results if r['errors'])
    warning_count = sum(1 for r in results if r['warnings'] and not r['errors'])

    report = {
        'summary': {
            'total_files': total,
            'with_frontmatter': sum(1 for r in results if r['has_frontmatter']),
            'error_count': error_count,
            'warning_count': warning_count,
            'success': error_count == 0
        },
        'results': results
    }

    print(json.dumps(report, indent=2, ensure_ascii=False))

    if error_count > 0:
        return 1
    elif warning_count > 0:
        return 2
    return 0

# =============================================================================
# ãƒ¡ã‚¤ãƒ³
# =============================================================================

def main():
    parser = argparse.ArgumentParser(
        description='9251205claude.mdãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯æº–æ‹ ãƒ•ãƒ­ãƒ³ãƒˆãƒã‚¿ãƒ¼æ¤œè¨¼'
    )
    parser.add_argument(
        '--format', choices=['text', 'json'], default='text',
        help='å‡ºåŠ›å½¢å¼ (default: text)'
    )
    parser.add_argument(
        '--schema-dir', type=Path,
        help='ã‚¹ã‚­ãƒ¼ãƒãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã¸ã®ãƒ‘ã‚¹'
    )
    parser.add_argument(
        '--check-sections', action='store_true',
        help='å¿…é ˆã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚‚æ¤œè¨¼ã™ã‚‹'
    )
    parser.add_argument(
        '--base-dir', type=Path,
        default=Path('/mnt/j/pcloud_sync/5agent/1conf/3doca/01-doc-framework'),
        help='æ¤œè¨¼å¯¾è±¡ã®ãƒ™ãƒ¼ã‚¹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª'
    )

    args = parser.parse_args()

    # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚¹ã‚­ãƒ¼ãƒãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
    if args.check_sections and not args.schema_dir:
        args.schema_dir = args.base_dir / 'schema'

    results = check_files(args.base_dir, args.schema_dir, args.check_sections)

    if args.format == 'json':
        exit_code = print_json_report(results)
    else:
        exit_code = print_text_report(results)

    sys.exit(exit_code)

if __name__ == '__main__':
    main()
